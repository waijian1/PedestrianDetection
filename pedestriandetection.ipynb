{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Check CUDA availability\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Check if CUDA (GPU support) is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for Non-Maximum Suppression (NMS) and minimum confidence threshold\n",
    "NMS_THRESHOLD = 0.3\n",
    "MIN_CONFIDENCE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect pedestrians in an image\n",
    "def pedestrian_detection(image, model, layer_name, personidz=0):\n",
    "    (H, W) = image.shape[:2]  # Get image dimensions\n",
    "    results = []\n",
    "\n",
    "    # Create a blob from the image\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    model.setInput(blob)  # Set the blob as input to the model\n",
    "    layerOutputs = model.forward(layer_name)  # Get outputs from the model's layers\n",
    "\n",
    "    boxes = []  # List to hold bounding boxes\n",
    "    centroids = []  # List to hold centroids of detected objects\n",
    "    confidences = []  # List to hold confidence scores\n",
    "\n",
    "    # Loop over each output layer\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]  # Get scores for each class\n",
    "            classID = np.argmax(scores)  # Get the class with the highest score\n",
    "            confidence = scores[classID]  # Get the confidence score\n",
    "\n",
    "            # If the detected object is a person and confidence is above the threshold\n",
    "            if classID == personidz and confidence > MIN_CONFIDENCE:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])  # Scale the bounding box\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")  # Get bounding box details\n",
    "\n",
    "                # Calculate top-left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])  # Append the bounding box\n",
    "                centroids.append((centerX, centerY))  # Append the centroid\n",
    "                confidences.append(float(confidence))  # Append the confidence score\n",
    "\n",
    "    # Apply Non-Maximum Suppression to suppress weak and overlapping bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONFIDENCE, NMS_THRESHOLD)\n",
    "\n",
    "    # Ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            # Get the bounding box and centroid for the detection\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(r)  # Append the result\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the COCO class labels that the model was trained on\n",
    "labelsPath = \"coco.names\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# Load the YOLO model weights and configuration\n",
    "weights_path = \"yolov4-tiny.weights\"\n",
    "config_path = \"yolov4-tiny.cfg\"\n",
    "\n",
    "model = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# Set preferable target to CUDA if available\n",
    "model.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "model.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the output layer names from the YOLO model\n",
    "layer_name = model.getLayerNames()\n",
    "layer_name = [layer_name[i - 1] for i in model.getUnconnectedOutLayers()]\n",
    "cap = cv2.VideoCapture(\"pedestrian-video.mp4\")\n",
    "writer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the frames from the video stream\n",
    "while True:\n",
    "\t(grabbed, image) = cap.read()  # Grab a frame\n",
    "\n",
    "\tif not grabbed: # If no frame was grabbed, break the loop\n",
    "\t\tbreak\n",
    "\timage = imutils.resize(image, width=700) # Resize the frame for faster processing\n",
    "\tresults = pedestrian_detection(image, model, layer_name,\n",
    "\t\tpersonidz=LABELS.index(\"person\")) # Detect pedestrians\n",
    "\n",
    "\t# Loop over the results and draw bounding boxes\n",
    "\tfor res in results:\n",
    "\t\tcv2.rectangle(image, (res[1][0],res[1][1]), (res[1][2],res[1][3]), (0, 255, 0), 2)\n",
    "\n",
    "\tcv2.imshow(\"Detection\",image) # Display the resulting frame\n",
    "\n",
    "\tkey = cv2.waitKey(1)\n",
    "\tif key == 27: # If 'ESC' key is pressed, break the loop\n",
    "\t\tbreak\n",
    "\n",
    "# Release the video stream and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c97697c55ae32387678cc8b9041d33bb1bb3f52af26387b80c5170262a755403"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
